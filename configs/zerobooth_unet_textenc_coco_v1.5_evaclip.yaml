output_dir: "output/pretrain-20221231-unet-textenc-coco-v1.5_evaclip"
logging_dir: "logs"

seed: 1337

# transform
image_size: 224
tgt_image_size: 512

model:
  train_text_encoder: True
  train_unet: True

  # stable diffusion and scheduler
  # pretrained_model_name_or_path: "CompVis/stable-diffusion-v1-4"
  pretrained_model_name_or_path: "runwayml/stable-diffusion-v1-5"
  # tune_num_layers_sd_text_encoder: 2
  revision: null

  # BLIP
  text_model: 'bert-base-uncased'

  finetuned: "/export/home/workspace/dreambooth/diffusers/BLIP2/pretrain_blipv2/eva_clip.pth"

  vision_model: "evaclip"
  image_size: 224
  # tgt_image_size: 512
  # batch_size: 16

  cross_attention_freq: 2

  num_query_token: 32
  max_text_length: 32
  embed_dim: 256

  num_proj_query_token: 32
  # num_proj_query_token: 4

  use_grad_checkpointing: True

# optimization
train_batch_size: 1
gradient_accumulation_steps: 2

learning_rate: 2e-6
lr_scheduler: constant
lr_warmup_steps: 0
scale_lr: False

adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 1e-02
adam_epsilon: 1e-08

max_grad_norm: 20.0
mixed_precision: "no"  # ["no", "fp16", "bf16"] 

max_train_steps: 80000
save_steps: 10000
logging_steps: 200

# distribution
local_rank: -1