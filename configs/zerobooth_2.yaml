output_dir: "output/pretrain-20221211-bs=3-nq=8-prenorm-norm_clip=all_tune=4"
logging_dir: "logs"

seed: 1337

# transform
image_size: 392
tgt_image_size: 512

model:
  train_text_encoder: True
  train_unet: False

  # stable diffusion and scheduler
  pretrained_model_name_or_path: "CompVis/stable-diffusion-v1-4"
  tune_num_layers_sd_text_encoder: 6
  revision: null

  # BLIP
  text_model: 'bert-base-uncased'

  pretrained: "/export/home/workspace/dreambooth/diffusers/BLIP2/pretrain_blipv2/checkpoint_14.pth"
  finetuned: '/export/home/workspace/dreambooth/diffusers/BLIP2/pretrain_blipv2/checkpoint_best.pth'

  vision_model: "clip"
  image_size: 392
  # tgt_image_size: 512
  # batch_size: 16

  num_query_token: 32
  max_text_length: 32
  embed_dim: 256

  use_grad_checkpointing: True

# optimization
train_batch_size: 3
gradient_accumulation_steps: 1

learning_rate: 1e-6
lr_scheduler: constant
lr_warmup_steps: 0
scale_lr: False

adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 1e-02
adam_epsilon: 1e-08

max_grad_norm: 1.0
mixed_precision: "no"  # ["no", "fp16", "bf16"] 

max_train_steps: 100000
save_steps: 5000
logging_steps: 200

# distribution
local_rank: -1