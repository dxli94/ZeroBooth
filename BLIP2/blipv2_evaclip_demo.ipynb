{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.blipv2_bert import blip_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "config = yaml.load(open(\"configs/pretrain_blip_evaclip.yaml\", \"r\"), Loader=yaml.Loader)\n",
    "# config = yaml.load(open(\"configs/finetune.yaml\", \"r\"), Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['visual.norm.weight', 'visual.norm.bias', 'visual.head.weight', 'visual.head.bias', 'visual.blocks.39.norm1.weight', 'visual.blocks.39.norm1.bias', 'visual.blocks.39.attn.q_bias', 'visual.blocks.39.attn.v_bias', 'visual.blocks.39.attn.qkv.weight', 'visual.blocks.39.attn.proj.weight', 'visual.blocks.39.attn.proj.bias', 'visual.blocks.39.norm2.weight', 'visual.blocks.39.norm2.bias', 'visual.blocks.39.mlp.fc1.weight', 'visual.blocks.39.mlp.fc1.bias', 'visual.blocks.39.mlp.fc2.weight', 'visual.blocks.39.mlp.fc2.bias'])\n",
      "freeze cls_token\n",
      "freeze pos_embed\n",
      "freeze patch_embed.proj.weight\n",
      "freeze patch_embed.proj.bias\n",
      "freeze blocks.0.norm1.weight\n",
      "freeze blocks.0.norm1.bias\n",
      "freeze blocks.0.attn.q_bias\n",
      "freeze blocks.0.attn.v_bias\n",
      "freeze blocks.0.attn.qkv.weight\n",
      "freeze blocks.0.attn.proj.weight\n",
      "freeze blocks.0.attn.proj.bias\n",
      "freeze blocks.0.norm2.weight\n",
      "freeze blocks.0.norm2.bias\n",
      "freeze blocks.0.mlp.fc1.weight\n",
      "freeze blocks.0.mlp.fc1.bias\n",
      "freeze blocks.0.mlp.fc2.weight\n",
      "freeze blocks.0.mlp.fc2.bias\n",
      "freeze blocks.1.norm1.weight\n",
      "freeze blocks.1.norm1.bias\n",
      "freeze blocks.1.attn.q_bias\n",
      "freeze blocks.1.attn.v_bias\n",
      "freeze blocks.1.attn.qkv.weight\n",
      "freeze blocks.1.attn.proj.weight\n",
      "freeze blocks.1.attn.proj.bias\n",
      "freeze blocks.1.norm2.weight\n",
      "freeze blocks.1.norm2.bias\n",
      "freeze blocks.1.mlp.fc1.weight\n",
      "freeze blocks.1.mlp.fc1.bias\n",
      "freeze blocks.1.mlp.fc2.weight\n",
      "freeze blocks.1.mlp.fc2.bias\n",
      "freeze blocks.2.norm1.weight\n",
      "freeze blocks.2.norm1.bias\n",
      "freeze blocks.2.attn.q_bias\n",
      "freeze blocks.2.attn.v_bias\n",
      "freeze blocks.2.attn.qkv.weight\n",
      "freeze blocks.2.attn.proj.weight\n",
      "freeze blocks.2.attn.proj.bias\n",
      "freeze blocks.2.norm2.weight\n",
      "freeze blocks.2.norm2.bias\n",
      "freeze blocks.2.mlp.fc1.weight\n",
      "freeze blocks.2.mlp.fc1.bias\n",
      "freeze blocks.2.mlp.fc2.weight\n",
      "freeze blocks.2.mlp.fc2.bias\n",
      "freeze blocks.3.norm1.weight\n",
      "freeze blocks.3.norm1.bias\n",
      "freeze blocks.3.attn.q_bias\n",
      "freeze blocks.3.attn.v_bias\n",
      "freeze blocks.3.attn.qkv.weight\n",
      "freeze blocks.3.attn.proj.weight\n",
      "freeze blocks.3.attn.proj.bias\n",
      "freeze blocks.3.norm2.weight\n",
      "freeze blocks.3.norm2.bias\n",
      "freeze blocks.3.mlp.fc1.weight\n",
      "freeze blocks.3.mlp.fc1.bias\n",
      "freeze blocks.3.mlp.fc2.weight\n",
      "freeze blocks.3.mlp.fc2.bias\n",
      "freeze blocks.4.norm1.weight\n",
      "freeze blocks.4.norm1.bias\n",
      "freeze blocks.4.attn.q_bias\n",
      "freeze blocks.4.attn.v_bias\n",
      "freeze blocks.4.attn.qkv.weight\n",
      "freeze blocks.4.attn.proj.weight\n",
      "freeze blocks.4.attn.proj.bias\n",
      "freeze blocks.4.norm2.weight\n",
      "freeze blocks.4.norm2.bias\n",
      "freeze blocks.4.mlp.fc1.weight\n",
      "freeze blocks.4.mlp.fc1.bias\n",
      "freeze blocks.4.mlp.fc2.weight\n",
      "freeze blocks.4.mlp.fc2.bias\n",
      "freeze blocks.5.norm1.weight\n",
      "freeze blocks.5.norm1.bias\n",
      "freeze blocks.5.attn.q_bias\n",
      "freeze blocks.5.attn.v_bias\n",
      "freeze blocks.5.attn.qkv.weight\n",
      "freeze blocks.5.attn.proj.weight\n",
      "freeze blocks.5.attn.proj.bias\n",
      "freeze blocks.5.norm2.weight\n",
      "freeze blocks.5.norm2.bias\n",
      "freeze blocks.5.mlp.fc1.weight\n",
      "freeze blocks.5.mlp.fc1.bias\n",
      "freeze blocks.5.mlp.fc2.weight\n",
      "freeze blocks.5.mlp.fc2.bias\n",
      "freeze blocks.6.norm1.weight\n",
      "freeze blocks.6.norm1.bias\n",
      "freeze blocks.6.attn.q_bias\n",
      "freeze blocks.6.attn.v_bias\n",
      "freeze blocks.6.attn.qkv.weight\n",
      "freeze blocks.6.attn.proj.weight\n",
      "freeze blocks.6.attn.proj.bias\n",
      "freeze blocks.6.norm2.weight\n",
      "freeze blocks.6.norm2.bias\n",
      "freeze blocks.6.mlp.fc1.weight\n",
      "freeze blocks.6.mlp.fc1.bias\n",
      "freeze blocks.6.mlp.fc2.weight\n",
      "freeze blocks.6.mlp.fc2.bias\n",
      "freeze blocks.7.norm1.weight\n",
      "freeze blocks.7.norm1.bias\n",
      "freeze blocks.7.attn.q_bias\n",
      "freeze blocks.7.attn.v_bias\n",
      "freeze blocks.7.attn.qkv.weight\n",
      "freeze blocks.7.attn.proj.weight\n",
      "freeze blocks.7.attn.proj.bias\n",
      "freeze blocks.7.norm2.weight\n",
      "freeze blocks.7.norm2.bias\n",
      "freeze blocks.7.mlp.fc1.weight\n",
      "freeze blocks.7.mlp.fc1.bias\n",
      "freeze blocks.7.mlp.fc2.weight\n",
      "freeze blocks.7.mlp.fc2.bias\n",
      "freeze blocks.8.norm1.weight\n",
      "freeze blocks.8.norm1.bias\n",
      "freeze blocks.8.attn.q_bias\n",
      "freeze blocks.8.attn.v_bias\n",
      "freeze blocks.8.attn.qkv.weight\n",
      "freeze blocks.8.attn.proj.weight\n",
      "freeze blocks.8.attn.proj.bias\n",
      "freeze blocks.8.norm2.weight\n",
      "freeze blocks.8.norm2.bias\n",
      "freeze blocks.8.mlp.fc1.weight\n",
      "freeze blocks.8.mlp.fc1.bias\n",
      "freeze blocks.8.mlp.fc2.weight\n",
      "freeze blocks.8.mlp.fc2.bias\n",
      "freeze blocks.9.norm1.weight\n",
      "freeze blocks.9.norm1.bias\n",
      "freeze blocks.9.attn.q_bias\n",
      "freeze blocks.9.attn.v_bias\n",
      "freeze blocks.9.attn.qkv.weight\n",
      "freeze blocks.9.attn.proj.weight\n",
      "freeze blocks.9.attn.proj.bias\n",
      "freeze blocks.9.norm2.weight\n",
      "freeze blocks.9.norm2.bias\n",
      "freeze blocks.9.mlp.fc1.weight\n",
      "freeze blocks.9.mlp.fc1.bias\n",
      "freeze blocks.9.mlp.fc2.weight\n",
      "freeze blocks.9.mlp.fc2.bias\n",
      "freeze blocks.10.norm1.weight\n",
      "freeze blocks.10.norm1.bias\n",
      "freeze blocks.10.attn.q_bias\n",
      "freeze blocks.10.attn.v_bias\n",
      "freeze blocks.10.attn.qkv.weight\n",
      "freeze blocks.10.attn.proj.weight\n",
      "freeze blocks.10.attn.proj.bias\n",
      "freeze blocks.10.norm2.weight\n",
      "freeze blocks.10.norm2.bias\n",
      "freeze blocks.10.mlp.fc1.weight\n",
      "freeze blocks.10.mlp.fc1.bias\n",
      "freeze blocks.10.mlp.fc2.weight\n",
      "freeze blocks.10.mlp.fc2.bias\n",
      "freeze blocks.11.norm1.weight\n",
      "freeze blocks.11.norm1.bias\n",
      "freeze blocks.11.attn.q_bias\n",
      "freeze blocks.11.attn.v_bias\n",
      "freeze blocks.11.attn.qkv.weight\n",
      "freeze blocks.11.attn.proj.weight\n",
      "freeze blocks.11.attn.proj.bias\n",
      "freeze blocks.11.norm2.weight\n",
      "freeze blocks.11.norm2.bias\n",
      "freeze blocks.11.mlp.fc1.weight\n",
      "freeze blocks.11.mlp.fc1.bias\n",
      "freeze blocks.11.mlp.fc2.weight\n",
      "freeze blocks.11.mlp.fc2.bias\n",
      "freeze blocks.12.norm1.weight\n",
      "freeze blocks.12.norm1.bias\n",
      "freeze blocks.12.attn.q_bias\n",
      "freeze blocks.12.attn.v_bias\n",
      "freeze blocks.12.attn.qkv.weight\n",
      "freeze blocks.12.attn.proj.weight\n",
      "freeze blocks.12.attn.proj.bias\n",
      "freeze blocks.12.norm2.weight\n",
      "freeze blocks.12.norm2.bias\n",
      "freeze blocks.12.mlp.fc1.weight\n",
      "freeze blocks.12.mlp.fc1.bias\n",
      "freeze blocks.12.mlp.fc2.weight\n",
      "freeze blocks.12.mlp.fc2.bias\n",
      "freeze blocks.13.norm1.weight\n",
      "freeze blocks.13.norm1.bias\n",
      "freeze blocks.13.attn.q_bias\n",
      "freeze blocks.13.attn.v_bias\n",
      "freeze blocks.13.attn.qkv.weight\n",
      "freeze blocks.13.attn.proj.weight\n",
      "freeze blocks.13.attn.proj.bias\n",
      "freeze blocks.13.norm2.weight\n",
      "freeze blocks.13.norm2.bias\n",
      "freeze blocks.13.mlp.fc1.weight\n",
      "freeze blocks.13.mlp.fc1.bias\n",
      "freeze blocks.13.mlp.fc2.weight\n",
      "freeze blocks.13.mlp.fc2.bias\n",
      "freeze blocks.14.norm1.weight\n",
      "freeze blocks.14.norm1.bias\n",
      "freeze blocks.14.attn.q_bias\n",
      "freeze blocks.14.attn.v_bias\n",
      "freeze blocks.14.attn.qkv.weight\n",
      "freeze blocks.14.attn.proj.weight\n",
      "freeze blocks.14.attn.proj.bias\n",
      "freeze blocks.14.norm2.weight\n",
      "freeze blocks.14.norm2.bias\n",
      "freeze blocks.14.mlp.fc1.weight\n",
      "freeze blocks.14.mlp.fc1.bias\n",
      "freeze blocks.14.mlp.fc2.weight\n",
      "freeze blocks.14.mlp.fc2.bias\n",
      "freeze blocks.15.norm1.weight\n",
      "freeze blocks.15.norm1.bias\n",
      "freeze blocks.15.attn.q_bias\n",
      "freeze blocks.15.attn.v_bias\n",
      "freeze blocks.15.attn.qkv.weight\n",
      "freeze blocks.15.attn.proj.weight\n",
      "freeze blocks.15.attn.proj.bias\n",
      "freeze blocks.15.norm2.weight\n",
      "freeze blocks.15.norm2.bias\n",
      "freeze blocks.15.mlp.fc1.weight\n",
      "freeze blocks.15.mlp.fc1.bias\n",
      "freeze blocks.15.mlp.fc2.weight\n",
      "freeze blocks.15.mlp.fc2.bias\n",
      "freeze blocks.16.norm1.weight\n",
      "freeze blocks.16.norm1.bias\n",
      "freeze blocks.16.attn.q_bias\n",
      "freeze blocks.16.attn.v_bias\n",
      "freeze blocks.16.attn.qkv.weight\n",
      "freeze blocks.16.attn.proj.weight\n",
      "freeze blocks.16.attn.proj.bias\n",
      "freeze blocks.16.norm2.weight\n",
      "freeze blocks.16.norm2.bias\n",
      "freeze blocks.16.mlp.fc1.weight\n",
      "freeze blocks.16.mlp.fc1.bias\n",
      "freeze blocks.16.mlp.fc2.weight\n",
      "freeze blocks.16.mlp.fc2.bias\n",
      "freeze blocks.17.norm1.weight\n",
      "freeze blocks.17.norm1.bias\n",
      "freeze blocks.17.attn.q_bias\n",
      "freeze blocks.17.attn.v_bias\n",
      "freeze blocks.17.attn.qkv.weight\n",
      "freeze blocks.17.attn.proj.weight\n",
      "freeze blocks.17.attn.proj.bias\n",
      "freeze blocks.17.norm2.weight\n",
      "freeze blocks.17.norm2.bias\n",
      "freeze blocks.17.mlp.fc1.weight\n",
      "freeze blocks.17.mlp.fc1.bias\n",
      "freeze blocks.17.mlp.fc2.weight\n",
      "freeze blocks.17.mlp.fc2.bias\n",
      "freeze blocks.18.norm1.weight\n",
      "freeze blocks.18.norm1.bias\n",
      "freeze blocks.18.attn.q_bias\n",
      "freeze blocks.18.attn.v_bias\n",
      "freeze blocks.18.attn.qkv.weight\n",
      "freeze blocks.18.attn.proj.weight\n",
      "freeze blocks.18.attn.proj.bias\n",
      "freeze blocks.18.norm2.weight\n",
      "freeze blocks.18.norm2.bias\n",
      "freeze blocks.18.mlp.fc1.weight\n",
      "freeze blocks.18.mlp.fc1.bias\n",
      "freeze blocks.18.mlp.fc2.weight\n",
      "freeze blocks.18.mlp.fc2.bias\n",
      "freeze blocks.19.norm1.weight\n",
      "freeze blocks.19.norm1.bias\n",
      "freeze blocks.19.attn.q_bias\n",
      "freeze blocks.19.attn.v_bias\n",
      "freeze blocks.19.attn.qkv.weight\n",
      "freeze blocks.19.attn.proj.weight\n",
      "freeze blocks.19.attn.proj.bias\n",
      "freeze blocks.19.norm2.weight\n",
      "freeze blocks.19.norm2.bias\n",
      "freeze blocks.19.mlp.fc1.weight\n",
      "freeze blocks.19.mlp.fc1.bias\n",
      "freeze blocks.19.mlp.fc2.weight\n",
      "freeze blocks.19.mlp.fc2.bias\n",
      "freeze blocks.20.norm1.weight\n",
      "freeze blocks.20.norm1.bias\n",
      "freeze blocks.20.attn.q_bias\n",
      "freeze blocks.20.attn.v_bias\n",
      "freeze blocks.20.attn.qkv.weight\n",
      "freeze blocks.20.attn.proj.weight\n",
      "freeze blocks.20.attn.proj.bias\n",
      "freeze blocks.20.norm2.weight\n",
      "freeze blocks.20.norm2.bias\n",
      "freeze blocks.20.mlp.fc1.weight\n",
      "freeze blocks.20.mlp.fc1.bias\n",
      "freeze blocks.20.mlp.fc2.weight\n",
      "freeze blocks.20.mlp.fc2.bias\n",
      "freeze blocks.21.norm1.weight\n",
      "freeze blocks.21.norm1.bias\n",
      "freeze blocks.21.attn.q_bias\n",
      "freeze blocks.21.attn.v_bias\n",
      "freeze blocks.21.attn.qkv.weight\n",
      "freeze blocks.21.attn.proj.weight\n",
      "freeze blocks.21.attn.proj.bias\n",
      "freeze blocks.21.norm2.weight\n",
      "freeze blocks.21.norm2.bias\n",
      "freeze blocks.21.mlp.fc1.weight\n",
      "freeze blocks.21.mlp.fc1.bias\n",
      "freeze blocks.21.mlp.fc2.weight\n",
      "freeze blocks.21.mlp.fc2.bias\n",
      "freeze blocks.22.norm1.weight\n",
      "freeze blocks.22.norm1.bias\n",
      "freeze blocks.22.attn.q_bias\n",
      "freeze blocks.22.attn.v_bias\n",
      "freeze blocks.22.attn.qkv.weight\n",
      "freeze blocks.22.attn.proj.weight\n",
      "freeze blocks.22.attn.proj.bias\n",
      "freeze blocks.22.norm2.weight\n",
      "freeze blocks.22.norm2.bias\n",
      "freeze blocks.22.mlp.fc1.weight\n",
      "freeze blocks.22.mlp.fc1.bias\n",
      "freeze blocks.22.mlp.fc2.weight\n",
      "freeze blocks.22.mlp.fc2.bias\n",
      "freeze blocks.23.norm1.weight\n",
      "freeze blocks.23.norm1.bias\n",
      "freeze blocks.23.attn.q_bias\n",
      "freeze blocks.23.attn.v_bias\n",
      "freeze blocks.23.attn.qkv.weight\n",
      "freeze blocks.23.attn.proj.weight\n",
      "freeze blocks.23.attn.proj.bias\n",
      "freeze blocks.23.norm2.weight\n",
      "freeze blocks.23.norm2.bias\n",
      "freeze blocks.23.mlp.fc1.weight\n",
      "freeze blocks.23.mlp.fc1.bias\n",
      "freeze blocks.23.mlp.fc2.weight\n",
      "freeze blocks.23.mlp.fc2.bias\n",
      "freeze blocks.24.norm1.weight\n",
      "freeze blocks.24.norm1.bias\n",
      "freeze blocks.24.attn.q_bias\n",
      "freeze blocks.24.attn.v_bias\n",
      "freeze blocks.24.attn.qkv.weight\n",
      "freeze blocks.24.attn.proj.weight\n",
      "freeze blocks.24.attn.proj.bias\n",
      "freeze blocks.24.norm2.weight\n",
      "freeze blocks.24.norm2.bias\n",
      "freeze blocks.24.mlp.fc1.weight\n",
      "freeze blocks.24.mlp.fc1.bias\n",
      "freeze blocks.24.mlp.fc2.weight\n",
      "freeze blocks.24.mlp.fc2.bias\n",
      "freeze blocks.25.norm1.weight\n",
      "freeze blocks.25.norm1.bias\n",
      "freeze blocks.25.attn.q_bias\n",
      "freeze blocks.25.attn.v_bias\n",
      "freeze blocks.25.attn.qkv.weight\n",
      "freeze blocks.25.attn.proj.weight\n",
      "freeze blocks.25.attn.proj.bias\n",
      "freeze blocks.25.norm2.weight\n",
      "freeze blocks.25.norm2.bias\n",
      "freeze blocks.25.mlp.fc1.weight\n",
      "freeze blocks.25.mlp.fc1.bias\n",
      "freeze blocks.25.mlp.fc2.weight\n",
      "freeze blocks.25.mlp.fc2.bias\n",
      "freeze blocks.26.norm1.weight\n",
      "freeze blocks.26.norm1.bias\n",
      "freeze blocks.26.attn.q_bias\n",
      "freeze blocks.26.attn.v_bias\n",
      "freeze blocks.26.attn.qkv.weight\n",
      "freeze blocks.26.attn.proj.weight\n",
      "freeze blocks.26.attn.proj.bias\n",
      "freeze blocks.26.norm2.weight\n",
      "freeze blocks.26.norm2.bias\n",
      "freeze blocks.26.mlp.fc1.weight\n",
      "freeze blocks.26.mlp.fc1.bias\n",
      "freeze blocks.26.mlp.fc2.weight\n",
      "freeze blocks.26.mlp.fc2.bias\n",
      "freeze blocks.27.norm1.weight\n",
      "freeze blocks.27.norm1.bias\n",
      "freeze blocks.27.attn.q_bias\n",
      "freeze blocks.27.attn.v_bias\n",
      "freeze blocks.27.attn.qkv.weight\n",
      "freeze blocks.27.attn.proj.weight\n",
      "freeze blocks.27.attn.proj.bias\n",
      "freeze blocks.27.norm2.weight\n",
      "freeze blocks.27.norm2.bias\n",
      "freeze blocks.27.mlp.fc1.weight\n",
      "freeze blocks.27.mlp.fc1.bias\n",
      "freeze blocks.27.mlp.fc2.weight\n",
      "freeze blocks.27.mlp.fc2.bias\n",
      "freeze blocks.28.norm1.weight\n",
      "freeze blocks.28.norm1.bias\n",
      "freeze blocks.28.attn.q_bias\n",
      "freeze blocks.28.attn.v_bias\n",
      "freeze blocks.28.attn.qkv.weight\n",
      "freeze blocks.28.attn.proj.weight\n",
      "freeze blocks.28.attn.proj.bias\n",
      "freeze blocks.28.norm2.weight\n",
      "freeze blocks.28.norm2.bias\n",
      "freeze blocks.28.mlp.fc1.weight\n",
      "freeze blocks.28.mlp.fc1.bias\n",
      "freeze blocks.28.mlp.fc2.weight\n",
      "freeze blocks.28.mlp.fc2.bias\n",
      "freeze blocks.29.norm1.weight\n",
      "freeze blocks.29.norm1.bias\n",
      "freeze blocks.29.attn.q_bias\n",
      "freeze blocks.29.attn.v_bias\n",
      "freeze blocks.29.attn.qkv.weight\n",
      "freeze blocks.29.attn.proj.weight\n",
      "freeze blocks.29.attn.proj.bias\n",
      "freeze blocks.29.norm2.weight\n",
      "freeze blocks.29.norm2.bias\n",
      "freeze blocks.29.mlp.fc1.weight\n",
      "freeze blocks.29.mlp.fc1.bias\n",
      "freeze blocks.29.mlp.fc2.weight\n",
      "freeze blocks.29.mlp.fc2.bias\n",
      "freeze blocks.30.norm1.weight\n",
      "freeze blocks.30.norm1.bias\n",
      "freeze blocks.30.attn.q_bias\n",
      "freeze blocks.30.attn.v_bias\n",
      "freeze blocks.30.attn.qkv.weight\n",
      "freeze blocks.30.attn.proj.weight\n",
      "freeze blocks.30.attn.proj.bias\n",
      "freeze blocks.30.norm2.weight\n",
      "freeze blocks.30.norm2.bias\n",
      "freeze blocks.30.mlp.fc1.weight\n",
      "freeze blocks.30.mlp.fc1.bias\n",
      "freeze blocks.30.mlp.fc2.weight\n",
      "freeze blocks.30.mlp.fc2.bias\n",
      "freeze blocks.31.norm1.weight\n",
      "freeze blocks.31.norm1.bias\n",
      "freeze blocks.31.attn.q_bias\n",
      "freeze blocks.31.attn.v_bias\n",
      "freeze blocks.31.attn.qkv.weight\n",
      "freeze blocks.31.attn.proj.weight\n",
      "freeze blocks.31.attn.proj.bias\n",
      "freeze blocks.31.norm2.weight\n",
      "freeze blocks.31.norm2.bias\n",
      "freeze blocks.31.mlp.fc1.weight\n",
      "freeze blocks.31.mlp.fc1.bias\n",
      "freeze blocks.31.mlp.fc2.weight\n",
      "freeze blocks.31.mlp.fc2.bias\n",
      "freeze blocks.32.norm1.weight\n",
      "freeze blocks.32.norm1.bias\n",
      "freeze blocks.32.attn.q_bias\n",
      "freeze blocks.32.attn.v_bias\n",
      "freeze blocks.32.attn.qkv.weight\n",
      "freeze blocks.32.attn.proj.weight\n",
      "freeze blocks.32.attn.proj.bias\n",
      "freeze blocks.32.norm2.weight\n",
      "freeze blocks.32.norm2.bias\n",
      "freeze blocks.32.mlp.fc1.weight\n",
      "freeze blocks.32.mlp.fc1.bias\n",
      "freeze blocks.32.mlp.fc2.weight\n",
      "freeze blocks.32.mlp.fc2.bias\n",
      "freeze blocks.33.norm1.weight\n",
      "freeze blocks.33.norm1.bias\n",
      "freeze blocks.33.attn.q_bias\n",
      "freeze blocks.33.attn.v_bias\n",
      "freeze blocks.33.attn.qkv.weight\n",
      "freeze blocks.33.attn.proj.weight\n",
      "freeze blocks.33.attn.proj.bias\n",
      "freeze blocks.33.norm2.weight\n",
      "freeze blocks.33.norm2.bias\n",
      "freeze blocks.33.mlp.fc1.weight\n",
      "freeze blocks.33.mlp.fc1.bias\n",
      "freeze blocks.33.mlp.fc2.weight\n",
      "freeze blocks.33.mlp.fc2.bias\n",
      "freeze blocks.34.norm1.weight\n",
      "freeze blocks.34.norm1.bias\n",
      "freeze blocks.34.attn.q_bias\n",
      "freeze blocks.34.attn.v_bias\n",
      "freeze blocks.34.attn.qkv.weight\n",
      "freeze blocks.34.attn.proj.weight\n",
      "freeze blocks.34.attn.proj.bias\n",
      "freeze blocks.34.norm2.weight\n",
      "freeze blocks.34.norm2.bias\n",
      "freeze blocks.34.mlp.fc1.weight\n",
      "freeze blocks.34.mlp.fc1.bias\n",
      "freeze blocks.34.mlp.fc2.weight\n",
      "freeze blocks.34.mlp.fc2.bias\n",
      "freeze blocks.35.norm1.weight\n",
      "freeze blocks.35.norm1.bias\n",
      "freeze blocks.35.attn.q_bias\n",
      "freeze blocks.35.attn.v_bias\n",
      "freeze blocks.35.attn.qkv.weight\n",
      "freeze blocks.35.attn.proj.weight\n",
      "freeze blocks.35.attn.proj.bias\n",
      "freeze blocks.35.norm2.weight\n",
      "freeze blocks.35.norm2.bias\n",
      "freeze blocks.35.mlp.fc1.weight\n",
      "freeze blocks.35.mlp.fc1.bias\n",
      "freeze blocks.35.mlp.fc2.weight\n",
      "freeze blocks.35.mlp.fc2.bias\n",
      "freeze blocks.36.norm1.weight\n",
      "freeze blocks.36.norm1.bias\n",
      "freeze blocks.36.attn.q_bias\n",
      "freeze blocks.36.attn.v_bias\n",
      "freeze blocks.36.attn.qkv.weight\n",
      "freeze blocks.36.attn.proj.weight\n",
      "freeze blocks.36.attn.proj.bias\n",
      "freeze blocks.36.norm2.weight\n",
      "freeze blocks.36.norm2.bias\n",
      "freeze blocks.36.mlp.fc1.weight\n",
      "freeze blocks.36.mlp.fc1.bias\n",
      "freeze blocks.36.mlp.fc2.weight\n",
      "freeze blocks.36.mlp.fc2.bias\n",
      "freeze blocks.37.norm1.weight\n",
      "freeze blocks.37.norm1.bias\n",
      "freeze blocks.37.attn.q_bias\n",
      "freeze blocks.37.attn.v_bias\n",
      "freeze blocks.37.attn.qkv.weight\n",
      "freeze blocks.37.attn.proj.weight\n",
      "freeze blocks.37.attn.proj.bias\n",
      "freeze blocks.37.norm2.weight\n",
      "freeze blocks.37.norm2.bias\n",
      "freeze blocks.37.mlp.fc1.weight\n",
      "freeze blocks.37.mlp.fc1.bias\n",
      "freeze blocks.37.mlp.fc2.weight\n",
      "freeze blocks.37.mlp.fc2.bias\n",
      "freeze blocks.38.norm1.weight\n",
      "freeze blocks.38.norm1.bias\n",
      "freeze blocks.38.attn.q_bias\n",
      "freeze blocks.38.attn.v_bias\n",
      "freeze blocks.38.attn.qkv.weight\n",
      "freeze blocks.38.attn.proj.weight\n",
      "freeze blocks.38.attn.proj.bias\n",
      "freeze blocks.38.norm2.weight\n",
      "freeze blocks.38.norm2.bias\n",
      "freeze blocks.38.mlp.fc1.weight\n",
      "freeze blocks.38.mlp.fc1.bias\n",
      "freeze blocks.38.mlp.fc2.weight\n",
      "freeze blocks.38.mlp.fc2.bias\n",
      "cross_attention_freq: 2\n",
      "copy from bert.encoder.layer.0.intermediate.dense.weight to bert.encoder.layer.0.intermediate_query.dense.weight\n",
      "copy from bert.encoder.layer.0.intermediate.dense.bias to bert.encoder.layer.0.intermediate_query.dense.bias\n",
      "copy from bert.encoder.layer.0.output.dense.weight to bert.encoder.layer.0.output_query.dense.weight\n",
      "copy from bert.encoder.layer.0.output.dense.bias to bert.encoder.layer.0.output_query.dense.bias\n",
      "copy from bert.encoder.layer.0.output.LayerNorm.weight to bert.encoder.layer.0.output_query.LayerNorm.weight\n",
      "copy from bert.encoder.layer.0.output.LayerNorm.bias to bert.encoder.layer.0.output_query.LayerNorm.bias\n",
      "copy from bert.encoder.layer.1.intermediate.dense.weight to bert.encoder.layer.1.intermediate_query.dense.weight\n",
      "copy from bert.encoder.layer.1.intermediate.dense.bias to bert.encoder.layer.1.intermediate_query.dense.bias\n",
      "copy from bert.encoder.layer.1.output.dense.weight to bert.encoder.layer.1.output_query.dense.weight\n",
      "copy from bert.encoder.layer.1.output.dense.bias to bert.encoder.layer.1.output_query.dense.bias\n",
      "copy from bert.encoder.layer.1.output.LayerNorm.weight to bert.encoder.layer.1.output_query.LayerNorm.weight\n",
      "copy from bert.encoder.layer.1.output.LayerNorm.bias to bert.encoder.layer.1.output_query.LayerNorm.bias\n",
      "copy from bert.encoder.layer.2.intermediate.dense.weight to bert.encoder.layer.2.intermediate_query.dense.weight\n",
      "copy from bert.encoder.layer.2.intermediate.dense.bias to bert.encoder.layer.2.intermediate_query.dense.bias\n",
      "copy from bert.encoder.layer.2.output.dense.weight to bert.encoder.layer.2.output_query.dense.weight\n",
      "copy from bert.encoder.layer.2.output.dense.bias to bert.encoder.layer.2.output_query.dense.bias\n",
      "copy from bert.encoder.layer.2.output.LayerNorm.weight to bert.encoder.layer.2.output_query.LayerNorm.weight\n",
      "copy from bert.encoder.layer.2.output.LayerNorm.bias to bert.encoder.layer.2.output_query.LayerNorm.bias\n",
      "copy from bert.encoder.layer.3.intermediate.dense.weight to bert.encoder.layer.3.intermediate_query.dense.weight\n",
      "copy from bert.encoder.layer.3.intermediate.dense.bias to bert.encoder.layer.3.intermediate_query.dense.bias\n",
      "copy from bert.encoder.layer.3.output.dense.weight to bert.encoder.layer.3.output_query.dense.weight\n",
      "copy from bert.encoder.layer.3.output.dense.bias to bert.encoder.layer.3.output_query.dense.bias\n",
      "copy from bert.encoder.layer.3.output.LayerNorm.weight to bert.encoder.layer.3.output_query.LayerNorm.weight\n",
      "copy from bert.encoder.layer.3.output.LayerNorm.bias to bert.encoder.layer.3.output_query.LayerNorm.bias\n",
      "copy from bert.encoder.layer.4.intermediate.dense.weight to bert.encoder.layer.4.intermediate_query.dense.weight\n",
      "copy from bert.encoder.layer.4.intermediate.dense.bias to bert.encoder.layer.4.intermediate_query.dense.bias\n",
      "copy from bert.encoder.layer.4.output.dense.weight to bert.encoder.layer.4.output_query.dense.weight\n",
      "copy from bert.encoder.layer.4.output.dense.bias to bert.encoder.layer.4.output_query.dense.bias\n",
      "copy from bert.encoder.layer.4.output.LayerNorm.weight to bert.encoder.layer.4.output_query.LayerNorm.weight\n",
      "copy from bert.encoder.layer.4.output.LayerNorm.bias to bert.encoder.layer.4.output_query.LayerNorm.bias\n",
      "copy from bert.encoder.layer.5.intermediate.dense.weight to bert.encoder.layer.5.intermediate_query.dense.weight\n",
      "copy from bert.encoder.layer.5.intermediate.dense.bias to bert.encoder.layer.5.intermediate_query.dense.bias\n",
      "copy from bert.encoder.layer.5.output.dense.weight to bert.encoder.layer.5.output_query.dense.weight\n",
      "copy from bert.encoder.layer.5.output.dense.bias to bert.encoder.layer.5.output_query.dense.bias\n",
      "copy from bert.encoder.layer.5.output.LayerNorm.weight to bert.encoder.layer.5.output_query.LayerNorm.weight\n",
      "copy from bert.encoder.layer.5.output.LayerNorm.bias to bert.encoder.layer.5.output_query.LayerNorm.bias\n",
      "copy from bert.encoder.layer.6.intermediate.dense.weight to bert.encoder.layer.6.intermediate_query.dense.weight\n",
      "copy from bert.encoder.layer.6.intermediate.dense.bias to bert.encoder.layer.6.intermediate_query.dense.bias\n",
      "copy from bert.encoder.layer.6.output.dense.weight to bert.encoder.layer.6.output_query.dense.weight\n",
      "copy from bert.encoder.layer.6.output.dense.bias to bert.encoder.layer.6.output_query.dense.bias\n",
      "copy from bert.encoder.layer.6.output.LayerNorm.weight to bert.encoder.layer.6.output_query.LayerNorm.weight\n",
      "copy from bert.encoder.layer.6.output.LayerNorm.bias to bert.encoder.layer.6.output_query.LayerNorm.bias\n",
      "copy from bert.encoder.layer.7.intermediate.dense.weight to bert.encoder.layer.7.intermediate_query.dense.weight\n",
      "copy from bert.encoder.layer.7.intermediate.dense.bias to bert.encoder.layer.7.intermediate_query.dense.bias\n",
      "copy from bert.encoder.layer.7.output.dense.weight to bert.encoder.layer.7.output_query.dense.weight\n",
      "copy from bert.encoder.layer.7.output.dense.bias to bert.encoder.layer.7.output_query.dense.bias\n",
      "copy from bert.encoder.layer.7.output.LayerNorm.weight to bert.encoder.layer.7.output_query.LayerNorm.weight\n",
      "copy from bert.encoder.layer.7.output.LayerNorm.bias to bert.encoder.layer.7.output_query.LayerNorm.bias\n",
      "copy from bert.encoder.layer.8.intermediate.dense.weight to bert.encoder.layer.8.intermediate_query.dense.weight\n",
      "copy from bert.encoder.layer.8.intermediate.dense.bias to bert.encoder.layer.8.intermediate_query.dense.bias\n",
      "copy from bert.encoder.layer.8.output.dense.weight to bert.encoder.layer.8.output_query.dense.weight\n",
      "copy from bert.encoder.layer.8.output.dense.bias to bert.encoder.layer.8.output_query.dense.bias\n",
      "copy from bert.encoder.layer.8.output.LayerNorm.weight to bert.encoder.layer.8.output_query.LayerNorm.weight\n",
      "copy from bert.encoder.layer.8.output.LayerNorm.bias to bert.encoder.layer.8.output_query.LayerNorm.bias\n",
      "copy from bert.encoder.layer.9.intermediate.dense.weight to bert.encoder.layer.9.intermediate_query.dense.weight\n",
      "copy from bert.encoder.layer.9.intermediate.dense.bias to bert.encoder.layer.9.intermediate_query.dense.bias\n",
      "copy from bert.encoder.layer.9.output.dense.weight to bert.encoder.layer.9.output_query.dense.weight\n",
      "copy from bert.encoder.layer.9.output.dense.bias to bert.encoder.layer.9.output_query.dense.bias\n",
      "copy from bert.encoder.layer.9.output.LayerNorm.weight to bert.encoder.layer.9.output_query.LayerNorm.weight\n",
      "copy from bert.encoder.layer.9.output.LayerNorm.bias to bert.encoder.layer.9.output_query.LayerNorm.bias\n",
      "copy from bert.encoder.layer.10.intermediate.dense.weight to bert.encoder.layer.10.intermediate_query.dense.weight\n",
      "copy from bert.encoder.layer.10.intermediate.dense.bias to bert.encoder.layer.10.intermediate_query.dense.bias\n",
      "copy from bert.encoder.layer.10.output.dense.weight to bert.encoder.layer.10.output_query.dense.weight\n",
      "copy from bert.encoder.layer.10.output.dense.bias to bert.encoder.layer.10.output_query.dense.bias\n",
      "copy from bert.encoder.layer.10.output.LayerNorm.weight to bert.encoder.layer.10.output_query.LayerNorm.weight\n",
      "copy from bert.encoder.layer.10.output.LayerNorm.bias to bert.encoder.layer.10.output_query.LayerNorm.bias\n",
      "copy from bert.encoder.layer.11.intermediate.dense.weight to bert.encoder.layer.11.intermediate_query.dense.weight\n",
      "copy from bert.encoder.layer.11.intermediate.dense.bias to bert.encoder.layer.11.intermediate_query.dense.bias\n",
      "copy from bert.encoder.layer.11.output.dense.weight to bert.encoder.layer.11.output_query.dense.weight\n",
      "copy from bert.encoder.layer.11.output.dense.bias to bert.encoder.layer.11.output_query.dense.bias\n",
      "copy from bert.encoder.layer.11.output.LayerNorm.weight to bert.encoder.layer.11.output_query.LayerNorm.weight\n",
      "copy from bert.encoder.layer.11.output.LayerNorm.bias to bert.encoder.layer.11.output_query.LayerNorm.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BLIP_Pretrain(\n",
       "  (visual_encoder): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.010526316240429878)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.021052632480859756)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.031578950583934784)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.04210526496171951)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.05263157933950424)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.06315790116786957)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.0736842155456543)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.08421052992343903)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.09473684430122375)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.10526315867900848)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.11578948050737381)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.12631580233573914)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.13684210181236267)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1473684310913086)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.15789474546909332)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.16842105984687805)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.17894737422466278)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1894736886024475)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.20000001788139343)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.21052631735801697)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.2210526466369629)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.23157896101474762)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.24210527539253235)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.2526315748691559)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.2631579041481018)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.27368420362472534)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.28421053290367126)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (28): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.2947368323802948)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (29): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.3052631616592407)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (30): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.31578946113586426)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (31): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.3263157904148102)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (32): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.3368421196937561)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (33): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.34736841917037964)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (34): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.35789474844932556)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (35): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.3684210479259491)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (36): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.378947377204895)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (37): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.38947367668151855)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (38): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.4000000059604645)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)\n",
       "  (text_model): BertLMHeadModel(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30523, 768)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=30523, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vision_proj): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (text_proj): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (itm_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "model = blip_pretrain(config=config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# state_dict = torch.load(\"pretrain_blipv2/checkpoint_14.pth\", map_location=\"cpu\")[\"model\"]\n",
    "state_dict = torch.load(\"pretrain_blipv2/eva_clip.pth\", map_location=\"cpu\")[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['layer.0.attention.self.query.weight', 'layer.0.attention.self.query.bias', 'layer.0.attention.self.key.weight', 'layer.0.attention.self.key.bias', 'layer.0.attention.self.value.weight', 'layer.0.attention.self.value.bias', 'layer.0.attention.output.dense.weight', 'layer.0.attention.output.dense.bias', 'layer.0.attention.output.LayerNorm.weight', 'layer.0.attention.output.LayerNorm.bias', 'layer.0.crossattention.self.query.weight', 'layer.0.crossattention.self.query.bias', 'layer.0.crossattention.self.key.weight', 'layer.0.crossattention.self.key.bias', 'layer.0.crossattention.self.value.weight', 'layer.0.crossattention.self.value.bias', 'layer.0.crossattention.output.dense.weight', 'layer.0.crossattention.output.dense.bias', 'layer.0.crossattention.output.LayerNorm.weight', 'layer.0.crossattention.output.LayerNorm.bias', 'layer.0.intermediate.dense.weight', 'layer.0.intermediate.dense.bias', 'layer.0.output.dense.weight', 'layer.0.output.dense.bias', 'layer.0.output.LayerNorm.weight', 'layer.0.output.LayerNorm.bias', 'layer.0.intermediate_query.dense.weight', 'layer.0.intermediate_query.dense.bias', 'layer.0.output_query.dense.weight', 'layer.0.output_query.dense.bias', 'layer.0.output_query.LayerNorm.weight', 'layer.0.output_query.LayerNorm.bias', 'layer.1.attention.self.query.weight', 'layer.1.attention.self.query.bias', 'layer.1.attention.self.key.weight', 'layer.1.attention.self.key.bias', 'layer.1.attention.self.value.weight', 'layer.1.attention.self.value.bias', 'layer.1.attention.output.dense.weight', 'layer.1.attention.output.dense.bias', 'layer.1.attention.output.LayerNorm.weight', 'layer.1.attention.output.LayerNorm.bias', 'layer.1.intermediate.dense.weight', 'layer.1.intermediate.dense.bias', 'layer.1.output.dense.weight', 'layer.1.output.dense.bias', 'layer.1.output.LayerNorm.weight', 'layer.1.output.LayerNorm.bias', 'layer.1.intermediate_query.dense.weight', 'layer.1.intermediate_query.dense.bias', 'layer.1.output_query.dense.weight', 'layer.1.output_query.dense.bias', 'layer.1.output_query.LayerNorm.weight', 'layer.1.output_query.LayerNorm.bias', 'layer.2.attention.self.query.weight', 'layer.2.attention.self.query.bias', 'layer.2.attention.self.key.weight', 'layer.2.attention.self.key.bias', 'layer.2.attention.self.value.weight', 'layer.2.attention.self.value.bias', 'layer.2.attention.output.dense.weight', 'layer.2.attention.output.dense.bias', 'layer.2.attention.output.LayerNorm.weight', 'layer.2.attention.output.LayerNorm.bias', 'layer.2.crossattention.self.query.weight', 'layer.2.crossattention.self.query.bias', 'layer.2.crossattention.self.key.weight', 'layer.2.crossattention.self.key.bias', 'layer.2.crossattention.self.value.weight', 'layer.2.crossattention.self.value.bias', 'layer.2.crossattention.output.dense.weight', 'layer.2.crossattention.output.dense.bias', 'layer.2.crossattention.output.LayerNorm.weight', 'layer.2.crossattention.output.LayerNorm.bias', 'layer.2.intermediate.dense.weight', 'layer.2.intermediate.dense.bias', 'layer.2.output.dense.weight', 'layer.2.output.dense.bias', 'layer.2.output.LayerNorm.weight', 'layer.2.output.LayerNorm.bias', 'layer.2.intermediate_query.dense.weight', 'layer.2.intermediate_query.dense.bias', 'layer.2.output_query.dense.weight', 'layer.2.output_query.dense.bias', 'layer.2.output_query.LayerNorm.weight', 'layer.2.output_query.LayerNorm.bias', 'layer.3.attention.self.query.weight', 'layer.3.attention.self.query.bias', 'layer.3.attention.self.key.weight', 'layer.3.attention.self.key.bias', 'layer.3.attention.self.value.weight', 'layer.3.attention.self.value.bias', 'layer.3.attention.output.dense.weight', 'layer.3.attention.output.dense.bias', 'layer.3.attention.output.LayerNorm.weight', 'layer.3.attention.output.LayerNorm.bias', 'layer.3.intermediate.dense.weight', 'layer.3.intermediate.dense.bias', 'layer.3.output.dense.weight', 'layer.3.output.dense.bias', 'layer.3.output.LayerNorm.weight', 'layer.3.output.LayerNorm.bias', 'layer.3.intermediate_query.dense.weight', 'layer.3.intermediate_query.dense.bias', 'layer.3.output_query.dense.weight', 'layer.3.output_query.dense.bias', 'layer.3.output_query.LayerNorm.weight', 'layer.3.output_query.LayerNorm.bias', 'layer.4.attention.self.query.weight', 'layer.4.attention.self.query.bias', 'layer.4.attention.self.key.weight', 'layer.4.attention.self.key.bias', 'layer.4.attention.self.value.weight', 'layer.4.attention.self.value.bias', 'layer.4.attention.output.dense.weight', 'layer.4.attention.output.dense.bias', 'layer.4.attention.output.LayerNorm.weight', 'layer.4.attention.output.LayerNorm.bias', 'layer.4.crossattention.self.query.weight', 'layer.4.crossattention.self.query.bias', 'layer.4.crossattention.self.key.weight', 'layer.4.crossattention.self.key.bias', 'layer.4.crossattention.self.value.weight', 'layer.4.crossattention.self.value.bias', 'layer.4.crossattention.output.dense.weight', 'layer.4.crossattention.output.dense.bias', 'layer.4.crossattention.output.LayerNorm.weight', 'layer.4.crossattention.output.LayerNorm.bias', 'layer.4.intermediate.dense.weight', 'layer.4.intermediate.dense.bias', 'layer.4.output.dense.weight', 'layer.4.output.dense.bias', 'layer.4.output.LayerNorm.weight', 'layer.4.output.LayerNorm.bias', 'layer.4.intermediate_query.dense.weight', 'layer.4.intermediate_query.dense.bias', 'layer.4.output_query.dense.weight', 'layer.4.output_query.dense.bias', 'layer.4.output_query.LayerNorm.weight', 'layer.4.output_query.LayerNorm.bias', 'layer.5.attention.self.query.weight', 'layer.5.attention.self.query.bias', 'layer.5.attention.self.key.weight', 'layer.5.attention.self.key.bias', 'layer.5.attention.self.value.weight', 'layer.5.attention.self.value.bias', 'layer.5.attention.output.dense.weight', 'layer.5.attention.output.dense.bias', 'layer.5.attention.output.LayerNorm.weight', 'layer.5.attention.output.LayerNorm.bias', 'layer.5.intermediate.dense.weight', 'layer.5.intermediate.dense.bias', 'layer.5.output.dense.weight', 'layer.5.output.dense.bias', 'layer.5.output.LayerNorm.weight', 'layer.5.output.LayerNorm.bias', 'layer.5.intermediate_query.dense.weight', 'layer.5.intermediate_query.dense.bias', 'layer.5.output_query.dense.weight', 'layer.5.output_query.dense.bias', 'layer.5.output_query.LayerNorm.weight', 'layer.5.output_query.LayerNorm.bias', 'layer.6.attention.self.query.weight', 'layer.6.attention.self.query.bias', 'layer.6.attention.self.key.weight', 'layer.6.attention.self.key.bias', 'layer.6.attention.self.value.weight', 'layer.6.attention.self.value.bias', 'layer.6.attention.output.dense.weight', 'layer.6.attention.output.dense.bias', 'layer.6.attention.output.LayerNorm.weight', 'layer.6.attention.output.LayerNorm.bias', 'layer.6.crossattention.self.query.weight', 'layer.6.crossattention.self.query.bias', 'layer.6.crossattention.self.key.weight', 'layer.6.crossattention.self.key.bias', 'layer.6.crossattention.self.value.weight', 'layer.6.crossattention.self.value.bias', 'layer.6.crossattention.output.dense.weight', 'layer.6.crossattention.output.dense.bias', 'layer.6.crossattention.output.LayerNorm.weight', 'layer.6.crossattention.output.LayerNorm.bias', 'layer.6.intermediate.dense.weight', 'layer.6.intermediate.dense.bias', 'layer.6.output.dense.weight', 'layer.6.output.dense.bias', 'layer.6.output.LayerNorm.weight', 'layer.6.output.LayerNorm.bias', 'layer.6.intermediate_query.dense.weight', 'layer.6.intermediate_query.dense.bias', 'layer.6.output_query.dense.weight', 'layer.6.output_query.dense.bias', 'layer.6.output_query.LayerNorm.weight', 'layer.6.output_query.LayerNorm.bias', 'layer.7.attention.self.query.weight', 'layer.7.attention.self.query.bias', 'layer.7.attention.self.key.weight', 'layer.7.attention.self.key.bias', 'layer.7.attention.self.value.weight', 'layer.7.attention.self.value.bias', 'layer.7.attention.output.dense.weight', 'layer.7.attention.output.dense.bias', 'layer.7.attention.output.LayerNorm.weight', 'layer.7.attention.output.LayerNorm.bias', 'layer.7.intermediate.dense.weight', 'layer.7.intermediate.dense.bias', 'layer.7.output.dense.weight', 'layer.7.output.dense.bias', 'layer.7.output.LayerNorm.weight', 'layer.7.output.LayerNorm.bias', 'layer.7.intermediate_query.dense.weight', 'layer.7.intermediate_query.dense.bias', 'layer.7.output_query.dense.weight', 'layer.7.output_query.dense.bias', 'layer.7.output_query.LayerNorm.weight', 'layer.7.output_query.LayerNorm.bias', 'layer.8.attention.self.query.weight', 'layer.8.attention.self.query.bias', 'layer.8.attention.self.key.weight', 'layer.8.attention.self.key.bias', 'layer.8.attention.self.value.weight', 'layer.8.attention.self.value.bias', 'layer.8.attention.output.dense.weight', 'layer.8.attention.output.dense.bias', 'layer.8.attention.output.LayerNorm.weight', 'layer.8.attention.output.LayerNorm.bias', 'layer.8.crossattention.self.query.weight', 'layer.8.crossattention.self.query.bias', 'layer.8.crossattention.self.key.weight', 'layer.8.crossattention.self.key.bias', 'layer.8.crossattention.self.value.weight', 'layer.8.crossattention.self.value.bias', 'layer.8.crossattention.output.dense.weight', 'layer.8.crossattention.output.dense.bias', 'layer.8.crossattention.output.LayerNorm.weight', 'layer.8.crossattention.output.LayerNorm.bias', 'layer.8.intermediate.dense.weight', 'layer.8.intermediate.dense.bias', 'layer.8.output.dense.weight', 'layer.8.output.dense.bias', 'layer.8.output.LayerNorm.weight', 'layer.8.output.LayerNorm.bias', 'layer.8.intermediate_query.dense.weight', 'layer.8.intermediate_query.dense.bias', 'layer.8.output_query.dense.weight', 'layer.8.output_query.dense.bias', 'layer.8.output_query.LayerNorm.weight', 'layer.8.output_query.LayerNorm.bias', 'layer.9.attention.self.query.weight', 'layer.9.attention.self.query.bias', 'layer.9.attention.self.key.weight', 'layer.9.attention.self.key.bias', 'layer.9.attention.self.value.weight', 'layer.9.attention.self.value.bias', 'layer.9.attention.output.dense.weight', 'layer.9.attention.output.dense.bias', 'layer.9.attention.output.LayerNorm.weight', 'layer.9.attention.output.LayerNorm.bias', 'layer.9.intermediate.dense.weight', 'layer.9.intermediate.dense.bias', 'layer.9.output.dense.weight', 'layer.9.output.dense.bias', 'layer.9.output.LayerNorm.weight', 'layer.9.output.LayerNorm.bias', 'layer.9.intermediate_query.dense.weight', 'layer.9.intermediate_query.dense.bias', 'layer.9.output_query.dense.weight', 'layer.9.output_query.dense.bias', 'layer.9.output_query.LayerNorm.weight', 'layer.9.output_query.LayerNorm.bias', 'layer.10.attention.self.query.weight', 'layer.10.attention.self.query.bias', 'layer.10.attention.self.key.weight', 'layer.10.attention.self.key.bias', 'layer.10.attention.self.value.weight', 'layer.10.attention.self.value.bias', 'layer.10.attention.output.dense.weight', 'layer.10.attention.output.dense.bias', 'layer.10.attention.output.LayerNorm.weight', 'layer.10.attention.output.LayerNorm.bias', 'layer.10.crossattention.self.query.weight', 'layer.10.crossattention.self.query.bias', 'layer.10.crossattention.self.key.weight', 'layer.10.crossattention.self.key.bias', 'layer.10.crossattention.self.value.weight', 'layer.10.crossattention.self.value.bias', 'layer.10.crossattention.output.dense.weight', 'layer.10.crossattention.output.dense.bias', 'layer.10.crossattention.output.LayerNorm.weight', 'layer.10.crossattention.output.LayerNorm.bias', 'layer.10.intermediate.dense.weight', 'layer.10.intermediate.dense.bias', 'layer.10.output.dense.weight', 'layer.10.output.dense.bias', 'layer.10.output.LayerNorm.weight', 'layer.10.output.LayerNorm.bias', 'layer.10.intermediate_query.dense.weight', 'layer.10.intermediate_query.dense.bias', 'layer.10.output_query.dense.weight', 'layer.10.output_query.dense.bias', 'layer.10.output_query.LayerNorm.weight', 'layer.10.output_query.LayerNorm.bias', 'layer.11.attention.self.query.weight', 'layer.11.attention.self.query.bias', 'layer.11.attention.self.key.weight', 'layer.11.attention.self.key.bias', 'layer.11.attention.self.value.weight', 'layer.11.attention.self.value.bias', 'layer.11.attention.output.dense.weight', 'layer.11.attention.output.dense.bias', 'layer.11.attention.output.LayerNorm.weight', 'layer.11.attention.output.LayerNorm.bias', 'layer.11.intermediate.dense.weight', 'layer.11.intermediate.dense.bias', 'layer.11.output.dense.weight', 'layer.11.output.dense.bias', 'layer.11.output.LayerNorm.weight', 'layer.11.output.LayerNorm.bias', 'layer.11.intermediate_query.dense.weight', 'layer.11.intermediate_query.dense.bias', 'layer.11.output_query.dense.weight', 'layer.11.output_query.dense.bias', 'layer.11.output_query.LayerNorm.weight', 'layer.11.output_query.LayerNorm.bias'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.text_model.bert.encoder.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "# from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "from constant import OPENAI_DATASET_MEAN, OPENAI_DATASET_STD\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(config['image_size'],interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(config['image_size']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(OPENAI_DATASET_MEAN, OPENAI_DATASET_STD),\n",
    "    ])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"../data/alvan-nee/alvan-nee-9M0tSjb-cpA-unsplash.jpeg\")\n",
    "image = transform_test(image).unsqueeze(0).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLIP_Pretrain(\n",
       "  (visual_encoder): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.010526316240429878)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.021052632480859756)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.031578950583934784)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.04210526496171951)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.05263157933950424)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.06315790116786957)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.0736842155456543)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.08421052992343903)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.09473684430122375)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.10526315867900848)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.11578948050737381)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.12631580233573914)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.13684210181236267)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1473684310913086)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.15789474546909332)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.16842105984687805)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.17894737422466278)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1894736886024475)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.20000001788139343)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.21052631735801697)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.2210526466369629)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.23157896101474762)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.24210527539253235)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.2526315748691559)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.2631579041481018)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.27368420362472534)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.28421053290367126)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (28): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.2947368323802948)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (29): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.3052631616592407)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (30): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.31578946113586426)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (31): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.3263157904148102)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (32): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.3368421196937561)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (33): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.34736841917037964)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (34): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.35789474844932556)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (35): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.3684210479259491)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (36): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.378947377204895)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (37): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.38947367668151855)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (38): Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.4000000059604645)\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)\n",
       "  (text_model): BertLMHeadModel(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30523, 768)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=30523, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vision_proj): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (text_proj): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (itm_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-10-d202f4b12d38&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">autocast_mode.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">198</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_autocast</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">195 │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">196 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_autocast</span>(*args, **kwargs):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>198 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_autocast                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">200 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/export/home/workspace/dreambooth/diffusers/BLIP2/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">blipv2_bert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">396</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393 │   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">394 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">395 │   │   │   # beam search</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>396 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.text_model.generate(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">397 │   │   │   │   </span>input_ids=input_ids,                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">398 │   │   │   │   </span>query_embeds=query_tokens,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">399 │   │   │   │   </span>max_length=max_length,                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">grad_mode.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">28</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 25 │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 26 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 27 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>():                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 28 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 29 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> cast(F, decorate_context)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 30 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 31 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrap_generator</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, func):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">generation_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1146</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1143 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">['Paris ist eines der dichtesten besiedelten Gebiete Europas.']</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1144 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">```\"\"\"</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1145 │   │   # 0. Validate model kwargs</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1146 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._validate_model_kwargs(model_kwargs.copy())                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1147 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1148 │   │   # 1. Set generation parameters if not already defined</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1149 │   │   </span>bos_token_id = bos_token_id <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> bos_token_id <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.bos_tok  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">generation_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">861</span> in                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_validate_model_kwargs</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 858 │   │   │   │   </span>unused_model_args.append(key)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 859 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 860 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> unused_model_args:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 861 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 862 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"The following `model_kwargs` are not used by the model: {</span>unused_model_  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 863 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" generate arguments will also show up in this list)\"</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 864 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>The following `model_kwargs` are not used by the model: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'encoder_hidden_states'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'encoder_attention_mask'</span><span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">(</span>note: typos in the generate arguments will also show up in this list<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-10-d202f4b12d38>\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/torch/\u001b[0m\u001b[1;33mautocast_mode.py\u001b[0m:\u001b[94m198\u001b[0m in \u001b[92mdecorate_autocast\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m196 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_autocast\u001b[0m(*args, **kwargs):                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m198 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m decorate_autocast                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/export/home/workspace/dreambooth/diffusers/BLIP2/models/\u001b[0m\u001b[1;33mblipv2_bert.py\u001b[0m:\u001b[94m396\u001b[0m in \u001b[92mgenerate\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m393 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m394 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m395 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# beam search\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m396 \u001b[2m│   │   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.text_model.generate(                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m397 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minput_ids=input_ids,                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m398 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mquery_embeds=query_tokens,                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m399 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmax_length=max_length,                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/torch/autograd/\u001b[0m\u001b[1;33mgrad_mode.py\u001b[0m:\u001b[94m28\u001b[0m in \u001b[92mdecorate_context\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 25 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 26 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 27 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.\u001b[91m__class__\u001b[0m():                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 28 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 29 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cast(F, decorate_context)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 30 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 31 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_wrap_generator\u001b[0m(\u001b[96mself\u001b[0m, func):                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/transformers/\u001b[0m\u001b[1;33mgeneration_utils.py\u001b[0m:\u001b[94m1146\u001b[0m in \u001b[92mgenerate\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1143 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m['Paris ist eines der dichtesten besiedelten Gebiete Europas.']\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1144 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m```\"\"\"\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1145 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# 0. Validate model kwargs\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1146 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._validate_model_kwargs(model_kwargs.copy())                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1147 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1148 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# 1. Set generation parameters if not already defined\u001b[0m                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1149 \u001b[0m\u001b[2m│   │   \u001b[0mbos_token_id = bos_token_id \u001b[94mif\u001b[0m bos_token_id \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.bos_tok  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/transformers/\u001b[0m\u001b[1;33mgeneration_utils.py\u001b[0m:\u001b[94m861\u001b[0m in                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_validate_model_kwargs\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 858 \u001b[0m\u001b[2m│   │   │   │   \u001b[0munused_model_args.append(key)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 859 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 860 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m unused_model_args:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 861 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 862 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mThe following `model_kwargs` are not used by the model: \u001b[0m\u001b[33m{\u001b[0munused_model_  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 863 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m generate arguments will also show up in this list)\u001b[0m\u001b[33m\"\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 864 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mThe following `model_kwargs` are not used by the model: \u001b[1m[\u001b[0m\u001b[32m'encoder_hidden_states'\u001b[0m, \n",
       "\u001b[32m'encoder_attention_mask'\u001b[0m\u001b[1m]\u001b[0m \u001b[1m(\u001b[0mnote: typos in the generate arguments will also show up in this list\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.generate(image=image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
