image_root: '/export/share/datasets/vision/coco/images/'
dataset: 'coco'
# image_root: '/export/share/datasets/vision/flickr30k/'
# dataset: 'flickr'
nocaps_image_root: '/export/share/datasets/vision/nocaps/'

coco_gt_root: 'annotation/coco_gt'
ann_root: 'annotation'
text_model: 'bert-base-uncased'

vision_model: "clip"
image_size: 392
tgt_image_size: 512
# batch_size: 16

num_query_token: 32
max_text_length: 32
embed_dim: 256

use_grad_checkpointing: True

# optimization
acc_grad_iters: 1
weight_decay: 0.05
max_epoch: 5
init_lr: 5e-6
min_lr: 5e-7
warmup_steps: 1000
warmup_lr: 1e-8

k: 128

pretrained: 'BLIP2/pretrain_blipv2/checkpoint_14.pth'
